跑154 epoch 需要432 min --> 7h10min
Test1:
	.
	106 → 96   , 全局的减均值，除方差，做jitter(s)变换
	learning_rate = 1e-3 固定 , moment = 0.3
	120 epoch 降到最低点; test_nll = 0.86437 , test_accuracy = 73.886%  , train_accuracy =  78.904%
	training 一张图片 4.56ms , test 一张图片1.51 ms , 训练一个epoch 大概2min30s
------------------------------------------------------------------------------------------------------------------
Test2:
	_m
	在test1的基础上仅仅是改变了moment的大小，moment = 0.9
	101 epoch 降到最低点； test_nll = 0.86535 , test_acuracy = 73.047% , train_accuracy = 77.495%
结论：
	与Test1相比，训练的结果基本没有明显好转，momnet可能并没有多大用处

---------------------------------------------------------------------------------------------------------------------
Test3:
	_md
	在test1和test2的基础上 set moment = 0
	learning_rate初始值为1e-3 , 60 epoch 后将leanring_rate 降低10倍 ， 120 epoch 后在继续将learning_rate降低10倍,在第一次降低10倍后，效果很明显。第二次降低的效果就不是很明显。第二次如果在100个epoch 左右降低10倍估计效果会好一些
在123个epoch后降到了 test_nll = 0.826 , test_accuracy = 74.145% , train_accuracy = 79.36%  
结论：
	在训练到一定的程度再来降低learning_rate明显是有效果的
----------------------------------------------------------------------------------------------------------------------

test4:
	-P
	在test3的基础上,将第二次的learning_rate下降该在100epoch，同时将数据预处理的方式变一下，将全局的减均值，方差归一 改成对于单张图片的减均值，除方差
	在130 epoch 降到最低点， test_nll = 0.83541, test_accuracy = 74.79%, train_accuracy = 79.066%
结论：
	 结果表明单张图片的处理要略微优于全局的处理
-----------------------------------------------------------------------------------------------------------------------
test5:
	-lcn
	在test4的基础上，仅仅在预处理的时候加上了LCN 部分，即在每张图片减均值方差归一之后进行局部size = 13的LCN 预处理。
	在 117 epoch 时降到最低点 test_nll = 0.86577, test_accuracy = 72.821% , train_accuracy = 78.233% 
结论：
	进行局部的LCN 貌似结果略微反而不好，可见LCN 作用不大
------------------------------------------------------------------------------------------------------------------------
test6:
	-average
	在test4的基础上，将validation集做了两种不同的处理以做比较，第一种保持原来的处理，第二种将之前360度随机旋转改成8个固定的角度，其他的一样，得到8张图片，输入进网络取平均值作为预测的结果。
	在139 epoch 时降到最低点 （average）test_nll = 0.80521, test_accuracy = 73.467%, 与之对比的第一种的结果（最低到0.846）： test_nll = 0.86442 , test_accuracy = 74.790% 
--------------------------------------------------------------------------------------------------------------------------
test7:
	-b
	在test6的基础上将图片的size进一步加大到112，结果一般
------------------------------------------------------------------------------------------------------------------------
test8:
	-b96
	重复test6,将test集做同样处理，生产csv文件
			  validation   test 
	epoch75 : 0.81427 --> 0.814544  
	epoch122:0.80260 --> 0.803602
------------------------------------------------------------------------------------------------------------------------
test9:
	-ratio
	在test8的基础上，仅仅是将图片scale时小于106的保持比例的放大，即在外围加上纯0的边，大于106的则缩小到106
    learningrate下降两次，
	第一次tolerance = 5 ,设置的不好，导致过早的降低了learningrate
	没有什么帮助，反而结果降低，结果在0.84左右(感觉是learningrate下降不合理的原因)
------------------------------------------------------------------------------------------------------------------------
test10:
	-try
	在test8的基础上做一些预处理上的改变
	1.train集将360度的随机旋转改为0,45,90,135,180,225,270,315等8个角度的随机旋转
	2.将crop改为translation(10pix以内x,y随机平移) 和scale
	3.learningrate 下降3次，以最佳的test_nll未更新的epoch数来作为tolerance,
	  第一次：tolerance = 9 ,下降一次, 1e-3 --> 1e-4, 0.84753 to 0.79628
	  第二次：tolerance = 15 ,下降两次，（写的有问题） 1e-4 --> 1e-6, 0.78936 to 0.79183

	best 107epoch 75.339% 0.78257(validation) --> 0.773640(test)
------------------------------------------------------------------------------------------------------------------------
test11:
	-tra
	在test10的基础上做一些learning_rate上的改进，并结合test9做预处理上的改进
	预处理
	读图片时，对于小于106的图片，在周边补0成106x106,大于106的则scale成106x106
	预处理时，采用8个角度的随机旋转
	train时，learningrate下降时采用每隔10的tolerance,learningrate = learningrate/5
	结果: 122epoch 0.81074,结果很一般
	原因：估计是读图片时保持scale比例的补0效果一般。
------------------------------------------------------------------------------------------------------------------------
test12:
	-try1
	在test10的基础上，将learningrate的下降改为test11的那样，每隔10的tolerance , learningrate = learningrate/5
	143epoch 75.726% 0.78094(validation) 0.775118(test)
------------------------------------------------------------------------------------------------------------------------
test13:
	在test12的基础上测试batchsize对于结果的影响
	初始learningRate = 1e-3,batchsize 改成32后下降超级慢，到100个epoch才到1.41
	初始learningRate = 1e-2,batchsize 32，下降速度较之前快，但还是比test12慢，174epoch,74.726%,0.79975
